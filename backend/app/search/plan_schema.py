"""Execution plan schema for adaptive RAG pipeline.

This module defines the structure and validation rules for query execution plans
generated by the LLM planning layer.
"""

from enum import Enum
from typing import Optional, Dict, Any
from pydantic import BaseModel, Field, field_validator


class QueryComplexity(str, Enum):
    """Query complexity classification."""
    SIMPLE = "simple"          # Single-fact queries: "What is X?"
    MODERATE = "moderate"      # Multi-aspect queries: "How does X work?"
    COMPLEX = "complex"        # Multi-faceted queries: "Compare X and Y"
    RESEARCH = "research"      # Deep analysis: "Comprehensive analysis of X"


class ExecutionStrategy(str, Enum):
    """RAG execution strategy."""
    DIRECT = "direct"                           # Simple: single retrieval + synthesis
    DECOMPOSE = "decompose_and_synthesize"      # Complex: multi-query retrieval
    ITERATIVE = "iterative_deep_dive"           # Research: adaptive retrieval


class SynthesisStyle(str, Enum):
    """Answer synthesis style."""
    CONCISE = "concise"          # 2-4 sentences, key facts only
    STRUCTURED = "structured"    # Organized sections with bullets
    COMPREHENSIVE = "comprehensive"  # Thorough analysis with full context


class ExecutionPlan(BaseModel):
    """Execution plan for query processing.

    This plan is generated by the LLM planning layer and guides the
    entire RAG pipeline execution.
    """

    # Query Analysis
    complexity: QueryComplexity = Field(
        ...,
        description="Classified complexity level of the query"
    )

    strategy: ExecutionStrategy = Field(
        ...,
        description="Chosen execution strategy based on query analysis"
    )

    reasoning: str = Field(
        ...,
        min_length=10,
        max_length=500,
        description="LLM's reasoning for choosing this plan (for debugging/monitoring)"
    )

    # Query Decomposition Settings
    use_decomposition: bool = Field(
        default=False,
        description="Whether to decompose query into sub-queries"
    )

    num_sub_queries: Optional[int] = Field(
        default=None,
        ge=2,
        le=5,
        description="Number of sub-queries to generate (if decomposition enabled)"
    )

    # Iterative Retrieval Settings
    use_iterative_retrieval: bool = Field(
        default=False,
        description="Whether to use iterative retrieval with self-assessment"
    )

    max_iterations: Optional[int] = Field(
        default=None,
        ge=1,
        le=5,
        description="Maximum iterations for iterative retrieval (if enabled)"
    )

    # Synthesis Settings
    synthesis_style: SynthesisStyle = Field(
        default=SynthesisStyle.CONCISE,
        description="Style of answer synthesis"
    )

    expected_answer_length: str = Field(
        default="medium",
        pattern="^(short|medium|long)$",
        description="Expected answer length: short (2-4 sentences), medium (1-2 paragraphs), long (multiple paragraphs)"
    )

    # Retrieval Configuration
    initial_retrieval_limit: int = Field(
        default=10,
        ge=5,
        le=40,
        description="Number of chunks to retrieve initially"
    )

    # Metadata (for tracking)
    confidence: Optional[float] = Field(
        default=None,
        ge=0.0,
        le=1.0,
        description="LLM's confidence in this plan (0-1 scale)"
    )

    @field_validator('num_sub_queries')
    @classmethod
    def validate_decomposition_config(cls, v, info):
        """Validate that decomposition settings are consistent."""
        use_decomposition = info.data.get('use_decomposition', False)

        if use_decomposition and v is None:
            raise ValueError("num_sub_queries required when use_decomposition=True")

        if not use_decomposition and v is not None:
            raise ValueError("num_sub_queries should be None when use_decomposition=False")

        return v

    @field_validator('max_iterations')
    @classmethod
    def validate_iterative_config(cls, v, info):
        """Validate that iterative retrieval settings are consistent."""
        use_iterative = info.data.get('use_iterative_retrieval', False)

        if use_iterative and v is None:
            raise ValueError("max_iterations required when use_iterative_retrieval=True")

        if not use_iterative and v is not None:
            raise ValueError("max_iterations should be None when use_iterative_retrieval=False")

        return v

    @field_validator('strategy')
    @classmethod
    def validate_strategy_consistency(cls, v, info):
        """Validate that strategy matches enabled features."""
        use_decomposition = info.data.get('use_decomposition', False)
        use_iterative = info.data.get('use_iterative_retrieval', False)

        if v == ExecutionStrategy.DIRECT:
            if use_decomposition or use_iterative:
                raise ValueError("DIRECT strategy incompatible with decomposition/iterative features")

        elif v == ExecutionStrategy.DECOMPOSE:
            if not use_decomposition:
                raise ValueError("DECOMPOSE strategy requires use_decomposition=True")

        elif v == ExecutionStrategy.ITERATIVE:
            if not use_iterative:
                raise ValueError("ITERATIVE strategy requires use_iterative_retrieval=True")

        return v

    def to_dict(self) -> Dict[str, Any]:
        """Convert plan to dictionary for logging."""
        return {
            "complexity": self.complexity.value,
            "strategy": self.strategy.value,
            "reasoning": self.reasoning,
            "use_decomposition": self.use_decomposition,
            "num_sub_queries": self.num_sub_queries,
            "use_iterative_retrieval": self.use_iterative_retrieval,
            "max_iterations": self.max_iterations,
            "synthesis_style": self.synthesis_style.value,
            "expected_answer_length": self.expected_answer_length,
            "initial_retrieval_limit": self.initial_retrieval_limit,
            "confidence": self.confidence
        }


class PlanValidationError(Exception):
    """Raised when an execution plan fails validation."""
    pass
